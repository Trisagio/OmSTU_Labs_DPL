# -*- coding: utf-8 -*-
"""CS:GO Round Winner Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QtpdtLx1xyaJ3G92n9UlU-4g9SQqqnHk

# Подготовка к обработке данных

## Подключение и преднастройка необходимых компонент

Подключение Google Drive
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # монтируем диск
# from google.colab import drive
# drive.mount('/content/drive')

"""Подключение глобально необходимых библиотек"""

# для отрисовки графиков
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
import random as rand

# для объединения в одну модель
from sklearn.pipeline import Pipeline

# для масштабирования
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler

# модули оценщика
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV

# для вывода результатов
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import accuracy_score, r2_score
from sklearn.metrics import mean_absolute_error, mean_squared_error

"""Инициализация константы для random_state"""

# для повторяемости результатов
SEED = 100

"""Настройка графиков"""

# Commented out IPython magic to ensure Python compatibility.
# преднастройка графиков
plt.style.use("fivethirtyeight")
sns.set_style('whitegrid')

# чтобы графики были в одном окне
# %matplotlib inline

"""Установка catboost"""

!pip install catboost

"""## Загрузка датасета

Чтение датасета, чтобы к нему можно было обратиться методами sklearn
"""

# загружаем данные с Google Drive
df = pd.read_csv('/content/drive/MyDrive/Динамические языки программирования/csgo_round_snapshots.csv')

"""Проверка типов данных столбцов и того, как их интерпретировал pandas"""

# выводим информацию о датасете
df.info()

"""Данный объем данных слишком велик для быстрого обучения моделей ресурсами, бесплатно предоставляемым в Google Colab.
Поэтому разумно ограничить объем выборки
"""

# выбираем случайные 20000 записей со всего датасета
# также задаем random_state для повторяемости результатов
df = df.sample(n=20000, random_state=SEED)

# выводим информацию о датасете
df.info()

"""## Анализ датасета

### Проверка статистики

Проверка на наличие отклонений важных характеристик числовых признаков: среднего арифметического, стандартного квадратичного отклонения, перцентилей, а также максимума и минимума
"""

# выводим статистику числовых записей датасета
df.describe()

"""Уточнение показателей для категориальных данных"""

# выводим статистику категориальных записей датасета
df.describe(include = [object, 'bool'])

"""Оценка категориальных признаков на наличие артефактов"""

# итерируемся по столбцам датасета
for name, values in df.items():
  if values.dtype != np.float64:
    print(f"{name}: {df[name].unique()}")

"""Проверка статистики по закладке бомб"""

# смотрим число закладок по картам
plt.figure(figsize=(12, 6))
ax = sns.countplot(x="map", hue="bomb_planted", data=df)
ax.set(title='Число закладок по каждой карте', xlabel='Карта', ylabel='Количество')
plt.show()

"""Проверка статистики по покупке саперных наборов"""

# смотрим количество саперных наборов в команде спецназа по картам
plt.figure(figsize=(12, 6))
ax = sns.countplot(x="map", hue="ct_defuse_kits", data=df)
ax.set(title='Число покупок по каждой карте', xlabel='Карта', ylabel='Количество')
plt.show()

"""Проверка распределения здоровья игроков"""

# рисуем распределение здоровья игроков
fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True, figsize=(12,6))
sns.kdeplot(df['ct_health'], fill=True, ax=ax1);
sns.kdeplot(df['t_health'], fill=True, ax=ax2);

"""Проверка распределения денег по командам"""

# рисуем распределение денег по командам
fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True, figsize=(12,6))
sns.kdeplot(df['ct_money'], fill=True, ax=ax1);
sns.kdeplot(df['t_money'], fill=True, ax=ax2);

"""Проверка распределения очков"""

# рисуем распределение очков
fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True, figsize=(12,6))
sns.kdeplot(df['ct_score'], fill=True, ax=ax1)
sns.kdeplot(df['t_score'], fill=True, ax=ax2)

"""Проверка распределения времени"""

# смотрим распределение времени
plt.figure(figsize=(10,6))
sns.kdeplot(df['time_left'], fill=True)

"""### Проверка сбалансированности"""

# смотрим счет команд по картам
plt.figure(figsize=(12, 6))
ax = sns.countplot(x="map", hue="round_winner", data=df)
ax.set(title='Победители по каждой карте', xlabel='Карта', ylabel='Счет')
plt.show()

"""Построение гистограммы распределения целевого признака «round_winner» для проверки сбалансированности"""

# смотрим общий счет команд
plt.figure(figsize=(8, 6))
sns.countplot(
    data=df,
    x='round_winner',
    hue='round_winner',
    palette=['#1b86ba', '#e36149']
)
plt.show()

"""На основании приведенных графиков можно сделать вывод о сбалансированности датасета

### Обобщение датасета

Создание обобщенного датасета
"""

"""# функция для определения типа оружия
def categorize_weapon(row):
    pistols = ['ct_weapon_deagle', 'ct_weapon_fiveseven', 'ct_weapon_usps', 'ct_weapon_p250', 'ct_weapon_p2000', 'ct_weapon_tec9']
    rifles = ['ct_weapon_ak47', 'ct_weapon_aug', 'ct_weapon_awp', 'ct_weapon_famas', 'ct_weapon_g3sg1', 'ct_weapon_galilar', 'ct_weapon_m4a1s', 'ct_weapon_m4a4', 'ct_weapon_m249', 'ct_weapon_sg553', 'ct_weapon_ssg08']
    shotguns = ['ct_weapon_nova', 'ct_weapon_sawedoff', 'ct_weapon_xm1014']
    smgs = ['ct_weapon_mac10', 'ct_weapon_mp5sd', 'ct_weapon_mp7', 'ct_weapon_mp9', 'ct_weapon_p90', 'ct_weapon_ump45']
    sniper_rifles = ['ct_weapon_awp', 'ct_weapon_g3sg1', 'ct_weapon_scar20']
    machine_guns = ['ct_weapon_m249', 'ct_weapon_negev']

    ct_weapon_pistols = sum(row[col] for col in pistols)
    ct_weapon_rifles = sum(row[col] for col in rifles)
    ct_weapon_shotguns = sum(row[col] for col in shotguns)
    ct_weapon_smgs = sum(row[col] for col in smgs)
    ct_weapon_sniper_rifles = sum(row[col] for col in sniper_rifles)
    ct_weapon_machine_guns = sum(row[col] for col in machine_guns)

    # аналогично для t_weapons
    t_weapon_pistols = sum(row[col.replace('ct_', 't_')] for col in pistols)
    t_weapon_rifles = sum(row[col.replace('ct_', 't_')] for col in rifles)
    t_weapon_shotguns = sum(row[col.replace('ct_', 't_')] for col in shotguns)
    t_weapon_smgs = sum(row[col.replace('ct_', 't_')] for col in smgs)
    t_weapon_sniper_rifles = sum(row[col.replace('ct_', 't_')] for col in sniper_rifles)
    t_weapon_machine_guns = sum(row[col.replace('ct_', 't_')] for col in machine_guns)

    return pd.Series([ct_weapon_pistols, ct_weapon_rifles, ct_weapon_shotguns, ct_weapon_smgs, ct_weapon_sniper_rifles, ct_weapon_machine_guns,
                      t_weapon_pistols, t_weapon_rifles, t_weapon_shotguns, t_weapon_smgs, t_weapon_sniper_rifles, t_weapon_machine_guns],
                     index=['ct_weapon_pistols', 'ct_weapon_rifles', 'ct_weapon_shotguns', 'ct_weapon_smgs', 'ct_weapon_sniper_rifles', 'ct_weapon_machine_guns',
                            't_weapon_pistols', 't_weapon_rifles', 't_weapon_shotguns', 't_weapon_smgs', 't_weapon_sniper_rifles', 't_weapon_machine_guns'])

grouped_df[['ct_weapon_pistols', 'ct_weapon_rifles', 'ct_weapon_shotguns', 'ct_weapon_smgs', 'ct_weapon_sniper_rifles', 'ct_weapon_machine_guns',
    't_weapon_pistols', 't_weapon_rifles', 't_weapon_shotguns', 't_weapon_smgs', 't_weapon_sniper_rifles', 't_weapon_machine_guns']] = grouped_df.apply(categorize_weapon, axis=1)

# определение списков для категорий оружия
pistols = ['ct_weapon_r8revolver', 't_weapon_r8revolver', 'ct_weapon_glock', 't_weapon_glock', 'ct_weapon_cz75auto', 't_weapon_cz75auto','ct_weapon_deagle', 'ct_weapon_fiveseven', 'ct_weapon_usps', 'ct_weapon_p250', 'ct_weapon_p2000', 'ct_weapon_tec9', 't_weapon_deagle', 't_weapon_fiveseven', 't_weapon_usps', 't_weapon_p250', 't_weapon_p2000', 't_weapon_tec9']
rifles = ['ct_weapon_elite', 't_weapon_elite', 't_weapon_ak47', 't_weapon_aug', 't_weapon_awp', 't_weapon_famas', 't_weapon_g3sg1', 't_weapon_galilar', 't_weapon_m4a1s', 't_weapon_m4a4', 't_weapon_m249', 't_weapon_sg553', 't_weapon_ssg08', 'ct_weapon_ak47', 'ct_weapon_aug', 'ct_weapon_awp', 'ct_weapon_famas', 'ct_weapon_g3sg1', 'ct_weapon_galilar', 'ct_weapon_m4a1s', 'ct_weapon_m4a4', 'ct_weapon_m249', 'ct_weapon_sg553', 'ct_weapon_ssg08']
shotguns = ['ct_weapon_mag7', 't_weapon_mag7', 't_weapon_nova', 't_weapon_sawedoff', 't_weapon_xm1014', 'ct_weapon_nova', 'ct_weapon_sawedoff', 'ct_weapon_xm1014']
smgs = ['t_weapon_mac10', 't_weapon_mp5sd', 't_weapon_mp7', 't_weapon_mp9', 't_weapon_p90', 't_weapon_ump45', 't_weapon_bizon', 'ct_weapon_bizon', 'ct_weapon_mac10', 'ct_weapon_mp5sd', 'ct_weapon_mp7', 'ct_weapon_mp9', 'ct_weapon_p90', 'ct_weapon_ump45']
sniper_rifles = ['t_weapon_awp', 't_weapon_g3sg1', 't_weapon_scar20', 'ct_weapon_awp', 'ct_weapon_g3sg1', 'ct_weapon_scar20']
machine_guns = ['t_weapon_m249', 't_weapon_negev', 'ct_weapon_m249', 'ct_weapon_negev']

grouped_df = grouped_df.drop(columns=pistols + rifles + shotguns + smgs + sniper_rifles + machine_guns)"""

# новый датасет для проверки корелляции
grouped_df = df

# создаем новые столбцы для сумм оружия и гранат для CT и T
grouped_df['ct_weapon'] = df[
    [col for col in df.columns if col.startswith('ct_weapon_')]].sum(axis=1)
grouped_df['t_weapon'] = df[
    [col for col in df.columns if col.startswith('t_weapon_')]].sum(axis=1)
grouped_df['ct_grenade'] = df[
    [col for col in df.columns if col.startswith('ct_grenade_')]].sum(axis=1)
grouped_df['t_grenade'] = df[
    [col for col in df.columns if col.startswith('t_grenade_')]].sum(axis=1)

# удаляем старые столбцы
grouped_df = grouped_df.drop([col for col in df.columns if col.startswith((
    'ct_weapon_', 't_weapon_', 'ct_grenade_', 't_grenade_'))], axis=1)

# выводим получившуюся структуру
grouped_df.info()

"""Прямое преобразование категориальных признаков в числовые"""

# переведем категориальный признак «map» в числовой
map_new = {
    'de_dust2' : 1,
    'de_mirage' : 2,
    'de_nuke': 3,
    'de_inferno': 4,
    'de_overpass': 5,
    'de_vertigo': 6,
    'de_train': 7,
    'de_cache': 8
}

grouped_df['map'] = grouped_df['map'].map(map_new).astype('uint8')

# переведем категориальный признак «bomb_planted» в числовой
bomb_planted_new = {
    False : 0,
    True : 1,
}

grouped_df['bomb_planted'] = grouped_df['bomb_planted'].map(bomb_planted_new).astype('uint8')

# переведем категориальный признак «round_winner» в числовой
round_winner_new = {
    'CT' : 0,
    'T' : 1,
}

grouped_df['round_winner'] = grouped_df['round_winner'].map(round_winner_new).astype('uint8')

"""Вывод случайной записи"""

# на всякий случай проверяем случайную запись
sample_index = rand.randint(0, len(grouped_df.round_winner) - 1)
print(grouped_df.iloc[sample_index])

"""### Проверка на наличие незначащих признаков

Проверка корреляции признаков
"""

# размер графика
plt.figure(figsize=(12, 10))

# таблица корреляции
sns.heatmap(grouped_df.corr(), annot=True, fmt=".1f");

"""Удаляем незначащий признак map"""

# удаляем ненужные столбцы
grouped_df = grouped_df.drop(['map'], axis=1)

# проверяем
grouped_df.info()

"""## Подготовка данных

### Заполнение отсутствующих значений

Проверка на наличие пропусков
"""

# отдельно считаем количество пустых записей в столбцах
skips_num = grouped_df.isna().sum()

print(f"Пропуски по столбцам:\n{skips_num}\n")

# выводим сумму по столбцам
print(f"Всего пропусков: {skips_num.sum()}")

"""### Выбор обучающего и тестового наборов

Разделение данных на те, по которым предсказываем, и на те, которые предсказываем
"""

# выбираем целевой признак
y_df = grouped_df.round_winner
# выбираем остальные признаки
X_df = grouped_df.drop(['round_winner'], axis=1)

"""# уберем малозначимые факторы
cols_grenade = 'grenade'
X_df = X_df.drop(X_df.columns[X_df.columns.str.contains(cols_grenade)], axis=1)
"""

# выводим на всякий случай
X_df.head()

"""Выделяем обучающую и тестовую выборки"""

# разделяем выборку
X_train, X_test, y_train, y_test = train_test_split(
    X_df, y_df, test_size = 0.2, random_state=SEED)

"""### Масштабирование признаков

Выбираем тип масштабирования
"""

# выбираем тип scaler'а
scaler = StandardScaler()

# скалируем
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# проверяем
X_train

"""# **ЛР1**

## Описание

Задание 1. Найти набор данных (датасет) для классификации удовлетворяющий следующим условиям: более 10 000 строк, более 20 столбцов, разные типы в столбцах, обязательно наличие целевого признака (таргета).
<br>
Задание 2 . Провести классификацию найденного датасета, методом к- ближайших соседей. В формате *Markdown* писать пояснения. Объяснить почему были выбраны именно такие гиперпараметры, была ли перекрестная проверка, и т.д.
<br><br>
P.S. Все решения выполнять в формате *Jupyter Notebook* и выкладывать на свои гитхабы.

## Решение

### Выбор датасета

На основании приведенных в описании 1 лаборатоной работы критериев, был выбран датасет по матчам компьютерной игры CS:GO. Целью работы является выявление победителя на основании заранее заданных параметров. Целевой показатель при этом может принимать 2 значения: победа команды террористов («T») или победа команды спецназа («CT»). Ссылка на используемый датасет приведена далее: https://www.kaggle.com/datasets/christianlillelund/csgo-round-winner-classification

### Подключение модулей
"""

# стандартный модуль KNN
from sklearn.neighbors import KNeighborsClassifier

"""### **sklearn.neighbors.KNeighborsClassifier**

---

#### По-умолчанию

Проверка модели с гиперпараметрами по-умолчанию
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# """# создание пайплайна
# pipeline_knn = Pipeline([
#     ('scaler', StandardScaler()),
#     ('knn', KNeighborsClassifier())
# ])"""
# 
# # создаем модель
# knn = KNeighborsClassifier()
# 
# # подаем на вход модели обучающие данные
# knn.fit(X_train, y_train)

"""Вывод результатов"""

# предсказываем результат на тестовой выборке
knn_pred = knn.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, knn_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, knn_pred)}\n')

"""#### С кросс-валидацией

Проведение процедуры кросс-валидации
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # задаем диапазон параметров
# # количество соседей
# k_range = [3, 5, 7, 9, 11, 13, 15]
# # сравним три стандартных алгоритма knn в sklearn
# algorithms = ['ball_tree', 'kd_tree', 'brute']
# # метрики расстояния в пространстве признаков
# metrics = [
#     'euclidean',
#     'manhattan',
#     'minkowski',
#     'chebyshev',
#     'hamming',
#     'canberra',
#     'braycurtis'
# ]
# 
# parameters = {
#     'n_neighbors': k_range, # число учитываемых соседей
#     'algorithm': algorithms, # алгоритмы поиска соседей
#     'weights': ['uniform', 'distance'], # веса соседей
#     'leaf_size': [10, 20, 30, 40], # размер листа, используемый в BallTree или KDTree
#     'metric': metrics, # метрики расстояния
# }
# 
# # подбираем лучшие параметры
# grid_knn = RandomizedSearchCV(
#     KNeighborsClassifier(),
#     parameters,
#     scoring='f1',
#     n_jobs = -1
# )
# 
# # обучаем модель
# grid_knn.fit(X_train, y_train)

"""Вывод результата кросс-валидации"""

# результаты кросс-валидации
print(f'Лучшие параметры:\n{grid_knn.best_params_}\n')
print("Показатель f1 для лучшей модели составил: {:.2f}%".
      format(grid_knn.best_score_ * 100) + '\n')

# предсказываем результат на тестовой выборке
grid_knn_pred = grid_knn.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, grid_knn_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, grid_knn_pred)}\n')

"""# **ЛР2**

## Описание

Задание 1 . Провести классификацию найденного датасета, методом машины опорных векторов. В формате *Markdown* писать пояснения. Объяснить почему были выбраны именно такие гиперпараметры, была ли перекрестная проверка, и т.д.
<br><br>
P.S. Все решения выполнять в формате *Jupyter Notebook* и выкладывать на свои гитхабы.

## Решение

### Подключение модулей

Метод машины опорных векторов
"""

# общий модуль для бинарной и многоклассовой классификации
from sklearn.svm import SVC

# специализированный модуль для классификации с линейным ядром
from sklearn.svm import LinearSVC

# модуль для обучения регуляризованных линейных моделей по стохастическому
# градиентному спуску. По-умолчанию обучает линейный SVM
from sklearn.linear_model import SGDClassifier

"""### **sklearn.linear_model.SGDClassifier**

---

#### По-умолчанию

Создание и обучение модели
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # создаем модель
# svm_sgdc = SGDClassifier()
# 
# # подаем на вход модели обучающие данные
# svm_sgdc.fit(X_train, y_train)

"""Вывод результата"""

# предсказываем результат на тестовой выборке
svm_sgdc_pred = svm_sgdc.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, svm_sgdc_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, svm_sgdc_pred)}\n')

"""#### С кросс-валидацией

Проведение процедуры кросс-валидации
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # задаем параметры
# parameters = {
#     'penalty': ['none', 'l2', 'l1', 'elasticnet'], # тип регуляризации
#     'alpha': [0.001, 0.01, 0.1, 1], # коэффициент регуляризации
#     'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], # стратегия изменения скорости обучения
#     'eta0': [0.01, 0.1, 0.2, 0.5], # начальная скорость обучения
#     'fit_intercept': [True, False], # следует ли добавлять константный член в линейную модель
#     'tol': [1e-3, 1e-4, 1e-5], # пороговое значение для оптимизации
#     'loss': ['hinge', 'log_loss', 'modified_huber', 'squared_hinge', 'perceptron'], # функция потерь
#     'l1_ratio': [0.0, 0.25, 0.5, 0.75, 1.0], # коэффициент для смешивания L1 и L2 регуляризации
#     'average': [True, False] # следует ли усреднять веса классов
# }
# 
# # подбираем лучшие параметры
# grid_svm_sgdc = RandomizedSearchCV(
#     SGDClassifier(),
#     parameters,
#     scoring='f1',
#     n_jobs = -1
# )
# # обучаем модель
# grid_svm_sgdc.fit(X_train, y_train)

"""Вывод результата кросс-валидации"""

# результаты кросс-валидации
print(f'Лучшие параметры:\n{grid_svm_sgdc.best_params_}\n')
print("Показатель f1 для лучшей модели составил: {:.2f}%".
      format(grid_svm_sgdc.best_score_ * 100) + '\n')

# предсказываем результат на тестовой выборке
grid_svm_sgdc_pred = grid_svm_sgdc.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, grid_svm_sgdc_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, grid_svm_sgdc_pred)}\n')

"""### **sklearn.svm.SVC**

---

#### По-умолчанию

Создание и обучение модели
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # создаем модель
# svm_svc = SVC()
# 
# # подаем на вход модели обучающие данные
# svm_svc.fit(X_train, y_train)

"""Вывод результата"""

# предсказываем результат на тестовой выборке
svm_svc_pred = svm_svc.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, svm_svc_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, svm_svc_pred)}\n')

"""#### С кросс-валидацией

Проведение процедуры кросс-валидации
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # задаем гиперпараметры
# parameters = {
#     'C': [0.1, 1], # коэффициент регуляризации
#     'kernel': ['poly', 'rbf', 'sigmoid'], # тип ядра
#     'degree': [4] # степень для 'poly' ядра
#     #'gamma': ['scale', 'auto'], # коэффициент ядра для 'rbf', 'poly' и 'sigmoid'
#     #'coef0': [0.0, 0.5, 1.0], # смещение для 'poly' и 'sigmoid'
#     #'tol': [1e-3, 1e-4], # пороговое значение для оптимизации
#     #'class_weight': [None, 'balanced'], # веса классов
# }
# 
# # подбираем лучшие параметры
# grid_svm_svc = RandomizedSearchCV(
#     SVC(),
#     parameters,
#     scoring='f1',
#     n_jobs = -1
# )
# 
# # обучаем модель
# grid_svm_svc.fit(X_train, y_train)

"""Вывод результата кросс-валидации"""

# результаты кросс-валидации
print(f'Лучшие параметры:\n{grid_svm_svc.best_params_}\n')
print("Показатель f1 для лучшей модели составил: {:.2f}%".
      format(grid_svm_svc.best_score_ * 100) + '\n')

# предсказываем результат на тестовой выборке
grid_svm_svc_pred = grid_svm_svc.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, grid_svm_svc_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, grid_svm_svc_pred)}\n')

"""### **sklearn.svm.LinearSVC**

---

#### По-умолчанию

Создание и обучение модели
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # создаем модель
# svm_lsvc = LinearSVC()
# 
# # подаем на вход модели обучающие данные
# svm_lsvc.fit(X_train, y_train)

"""Вывод результата"""

# предсказываем результат на тестовой выборке
svm_lsvc_pred = svm_lsvc.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, svm_lsvc_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, svm_lsvc_pred)}\n')

"""#### С кросс-валидацией

Проведение процедуры кросс-валидации
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # задаем диапазон параметров
# parameters = {
#     #'penalty': ['l1', 'l2'], # тип регуляризации, l2 по-умолчанию
#                              # l1 приводит к разреженным _coef
#     'loss': ['hinge', 'squared_hinge'], # функция потерь
#                                         # проверяем обе
#     #'dual': [True, False], # следует ли использовать двойственную форму задачи, True по-умолчанию
#                             # поскольку n_samples > n_features, берем двойственную
#     'tol': [1e-4, 1e-3], # пороговое значение для оптимизации, 1e-3 по-умолчанию
#     'C': [10], # коэффициент регуляризации
#                # проверяем методом научного тыка
#     #'fit_intercept': [True, False], # следует ли добавлять константный член (центрирование)
#                                      # True по-умолчанию
#     'intercept_scaling': [1, 10, 100], # масштабирование константного члена
#     #'class_weight': [None, 'balanced'] # веса классов
# }
# 
# # подбираем лучшие параметры
# grid_svm_lsvc = RandomizedSearchCV(LinearSVC(), parameters, scoring='f1', n_jobs=-1)
# # обучаем модель
# grid_svm_lsvc.fit(X_train, y_train)

"""Вывод результата кросс-валидации"""

# результаты кросс-валидации
print(f'Лучшие параметры:\n{grid_svm_lsvc.best_params_}\n')
print("Показатель f1 для лучшей модели составил: {:.2f}%".
      format(grid_svm_lsvc.best_score_ * 100) + '\n')

# предсказываем результат на тестовой выборке
grid_svm_lsvc_pred = grid_svm_lsvc.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, grid_svm_lsvc_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, grid_svm_lsvc_pred)}\n')

"""# **ЛР3**

## Описание

Задание 1 . Провести классификацию найденного датасета, методами линеной и логистической регрессий . В формате *Markdown* написать пояснения. Объяснить почему были выбраны именно такие гиперпараметры, была ли перекрестная проверка, и т.д.
<br><br>
P.S. Все решения выполнять в формате *Jupyter Notebook* и выкладывать на свои гитхабы.

## Решение

### Подключение модулей

Методы линейной регрессии
"""

# стандартная модель
from sklearn.linear_model import LinearRegression

# для комбинированных L1- и L2-регуляризаций
from sklearn.linear_model import ElasticNet

# для L1-регуляризации
from sklearn.linear_model import Lasso

# для L2-регуляризации
from sklearn.linear_model import Ridge

# для стохастического градиентного спуска
from sklearn.linear_model import SGDRegressor

"""Методы логистической регрессии"""

# стандартная модель, поддерживающая бинарную, One-vs-Rest и мультиномиальную
# логистическую регрессию с опциональной регуляризацией L1, L2 или Elastic-Net
from sklearn.linear_model import LogisticRegression

"""### **sklearn.linear_model.LinearRegression**

---

#### Проверка обычной регрессии

Создание и обучение модели
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # создаем модель
# regression_linear = LinearRegression()
# 
# # подаем на вход модели обучающие данные
# regression_linear.fit(X_train, y_train)

"""Вывод результата"""

# предсказываем результат на тестовой выборке
regression_linear_pred = regression_linear.predict(X_test)

# заводим переменные
mae = mean_absolute_error(y_test, regression_linear_pred)
mse = mean_squared_error(y_test, regression_linear_pred)

# оцениваем модель
print(f'MAE: {mae:.5f}')
print(f'MSE: {mse:.5f}')
print(f'RMSE: {np.sqrt(mse):.5f}')

"""### **sklearn.linear_model.LogisticRegression**

---

#### По-умолчанию

Создание и обучение модели
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # создаем модель
# regression_logistic = LogisticRegression()
# 
# # подаем на вход модели обучающие данные
# regression_logistic.fit(X_train, y_train)

"""Вывод результата"""

# предсказываем результат на тестовой выборке
regression_logistic_pred = regression_logistic.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, regression_logistic_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, regression_logistic_pred)}\n')

"""#### С кросс-валидацией

Проведение процедуры кросс-валидации
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # задаем диапазон параметров
# parameters = {
#     'penalty': ['l1', 'l2'], # тип регуляризации
#     'C': [0.001, 0.01, 0.1, 1, 10], # инверсное значение коэффициента регуляризации
#     #'fit_intercept': [True, False], # следует ли добавлять константный член в линейную модель
#     'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], # алгоритм оптимизации
#     #'tol': [1e-4, 1e-3], # пороговое значение для оптимизации
#     #'class_weight': [None, 'balanced'] # веса классов
# }
# 
# # подбираем лучшие параметры
# grid_regression_logistic = RandomizedSearchCV(
#     LogisticRegression(),
#     parameters,
#     scoring='f1',
#     n_jobs = -1
# )
# # обучаем модель
# grid_regression_logistic.fit(X_train, y_train)

"""Вывод результата кросс-валидации"""

# результаты кросс-валидации
print(f'Лучшие параметры:\n{grid_regression_logistic.best_params_}\n')
print("Показатель f1 для лучшей модели составил: {:.2f}%".
      format(grid_regression_logistic.best_score_ * 100) + '\n')

# предсказываем результат на тестовой выборке
grid_regression_logistic_pred = grid_regression_logistic.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, grid_regression_logistic_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, grid_regression_logistic_pred)}\n')

"""# **ЛР4**

## Описание

Задание 1 . Провести классификацию найденного датасета, методами наивного Байеса  . В формате *Markdown* написать пояснения. Объяснить почему были выбраны именно такие гиперпараметры, была ли перекрестная проверка, и т.д.
<br><br>
P.S. Все решения выполнять в формате *Jupyter Notebook* и выкладывать на свои гитхабы.

## Решение

### Подключение модулей
"""

# гауссовский наивный байесовский алгоритм для классификации
# когда вероятность появления признаков Гауссова
from sklearn.naive_bayes import GaussianNB

# для классификации текстовых документов, где признаки представляют собой частоты слов
from sklearn.naive_bayes import MultinomialNB

# для работы с бинарными признаками
from sklearn.naive_bayes import ComplementNB

# обобщение наивного байесовского классификатора, учитывающее
# дополнительные сведения о распределении признаков
from sklearn.naive_bayes import BernoulliNB

# для работы с категориальными признаками
from sklearn.naive_bayes import CategoricalNB

"""### **sklearn.naive_bayes.GaussianNB**

---

#### Обычная байесовская модель

Создание и обучение модели
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # вероятности классов - единственный параметр GaussianNB
# # priors по-умолчанию None (вычисляются на основе входных данных)
# """parameters = {'priors': [None]}"""
# 
# # создаем модель
# nb_gaussian = GaussianNB()
# 
# # подаем на вход модели обучающие данные
# nb_gaussian.fit(X_train, y_train)

"""Вывод результата"""

# предсказываем результат на тестовой выборке
nb_gaussian_pred = nb_gaussian.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, nb_gaussian_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, nb_gaussian_pred)}\n')

"""### **sklearn.naive_bayes.BernoulliNB**

---

#### По-умолчанию

Создание и обучение модели
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # создаем модель
# nb_bernoulli = BernoulliNB()
# 
# # подаем на вход модели обучающие данные
# nb_bernoulli.fit(X_train, y_train)

"""Вывод результата"""

# предсказываем результат на тестовой выборке
nb_bernoulli_pred = nb_bernoulli.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, nb_bernoulli_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, nb_bernoulli_pred)}\n')

"""#### С кросс-валидацией

Проведение процедуры кросс-валидации
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # задаем диапазон параметров
# parameters = {
#     'alpha': [0, 0.001, 0.01, 0.1, 1.0, 10.0], # аддитивное (Лапласа-Лидстоуна) сглаживание
#     'force_alpha': [True, False], # применять ли alpha, или ставить в 1e-10
#     'binarize': [None, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], # пороговое значение
#                                                                                # для бинаризации признаков
#     'fit_prior': [True, False], # следует ли использовать приоритеты классов, вычисленные из данных
#     #'class_prior': [None] #  вероятности классов, используемые в качестве приоритетов
# }
# 
# 
# # подбираем лучшие параметры
# grid_nb_bernoulli = GridSearchCV(
#     BernoulliNB(),
#     parameters,
#     scoring='f1',
#     n_jobs = -1
# )
# # обучаем модель
# grid_nb_bernoulli.fit(X_train, y_train)

"""Вывод результата кросс-валидации"""

# результаты кросс-валидации
print(f'Лучшие параметры:\n{grid_nb_bernoulli.best_params_}\n')
print("Показатель f1 для лучшей модели составил: {:.2f}%".
      format(grid_nb_bernoulli.best_score_ * 100) + '\n')

# предсказываем результат на тестовой выборке
grid_nb_bernoulli_pred = grid_nb_bernoulli.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, grid_nb_bernoulli_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, grid_nb_bernoulli_pred)}\n')

"""# **ЛР5**

## Описание

Задание 1 . Провести классификацию найденного датасета, методами решающего дерева и случайного леса . В формате *Markdown* написать пояснения. Объяснить почему были выбраны именно такие гиперпараметры, была ли перекрестная проверка, и т.д.
<br><br>
P.S. Все решения выполнять в формате *Jupyter Notebook* и выкладывать на свои гитхабы.

## Решение

### Подключение модулей
"""

# базовый классификатор, используемый внутри RandomForestClassifier и BaggingClassifier
from sklearn.tree import DecisionTreeClassifier

# классификатор на ансамбле случайных деревьев
from sklearn.ensemble import RandomForestClassifier

# классификатор использует метод Bagging
from sklearn.ensemble import BaggingClassifier

# классификатор использующий метод градиентного бустинга
from sklearn.ensemble import GradientBoostingClassifier

"""### **sklearn.tree.DecisionTreeClassifier**

---

#### По-умолчанию

Создание и обучение модели
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # создаем модель
# ensemble_tree = DecisionTreeClassifier()
# 
# # подаем на вход модели обучающие данные
# ensemble_tree.fit(X_train, y_train)

"""Вывод результата"""

# предсказываем результат на тестовой выборке
ensemble_tree_pred = ensemble_tree.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, ensemble_tree_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, ensemble_tree_pred)}\n')

"""#### С кросс-валидацией

Проведение процедуры кросс-валидации
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # задаем диапазон параметров
# parameters = {
#     'criterion': ['gini', 'entropy'], # функция для измерения качества разделения
#     'splitter': ['best', 'random'], # стратегия выбора признака для разделения
#     'max_depth': [None, 10, 20, 30, 40, 50], # максимальная глубина дерева
#     #'min_samples_split': [2, 5, 10, 20], # минимальное количество образцов для разделения узла
#     #'min_samples_leaf': [1, 2, 5, 10], # минимальное количество образцов для листа
#     #'min_weight_fraction_leaf': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], # минимальная доля веса образцов в листе
#     'max_features': [None, 'auto', 'sqrt', 'log2'], # количество признаков при поиске лучшего разделения
#     #'max_leaf_nodes': [None, 10, 20, 30, 40, 50], # максимальное количество листьев
#     #'min_impurity_decrease': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], # минимальное уменьшение неопределенности для разделения
#     'class_weight': [None, 'balanced', 'balanced_subsample'], # веса классов
#     'ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5] # параметр для контроля сжатия дерева
# }
# 
# # подбираем лучшие параметры
# grid_ensemble_tree = GridSearchCV(
#     DecisionTreeClassifier(),
#     parameters,
#     scoring='f1',
#     n_jobs = -1
# )
# # обучаем модель
# grid_ensemble_tree.fit(X_train, y_train)

"""Вывод результата кросс-валидации"""

# результаты кросс-валидации
print(f'Лучшие параметры:\n{grid_ensemble_tree.best_params_}\n')
print("Показатель f1 для лучшей модели составил: {:.2f}%".
      format(grid_ensemble_tree.best_score_ * 100) + '\n')

# предсказываем результат на тестовой выборке
grid_ensemble_tree_pred = grid_ensemble_tree.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, grid_ensemble_tree_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, grid_ensemble_tree_pred)}\n')

"""### **sklearn.ensemble.RandomForestClassifier**

---

#### По-умолчанию

Создание и обучение модели
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # создаем модель
# ensemble_randforest = RandomForestClassifier()
# 
# # подаем на вход модели обучающие данные
# ensemble_randforest.fit(X_train, y_train)

"""Вывод результата"""

# предсказываем результат на тестовой выборке
ensemble_randforest_pred = ensemble_randforest.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, ensemble_randforest_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, ensemble_randforest_pred)}\n')

"""#### С кросс-валидацией

Проведение процедуры кросс-валидации
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # задаем диапазон параметров
# parameters = {
#     'n_estimators': [100, 200], # количество деревьев в лесу
#     'criterion': ['gini', 'entropy'], # функция для измерения качества разделения
#     'max_depth': [None, 50, 100], # максимальная глубина дерева
#     #'min_samples_split': [2, 5, 10], # минимальное количество образцов для разделения узла
#     #'min_samples_leaf': [1, 2, 4], # минимальное количество образцов для листа
#     #'min_weight_fraction_leaf': [0.0, 0.1], # минимальная доля веса образцов в листе
#     'max_features': ['auto', 'sqrt', 'log2'], # количество признаков при поиске лучшего разделения
#     #'max_leaf_nodes': [None, 10, 20, 30, 40, 50], # максимальное количество листьев
#     #'min_impurity_decrease': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], # минимальное уменьшение неопределенности для разделения
#     #'bootstrap': [True, False], # следует ли использовать bootstrap-выборку при построении деревьев
#     'oob_score': [True, False], # следует ли использовать out-of-bag (OOB) оценку для оценки качества модели
#     #'class_weight': [None, 'balanced', 'balanced_subsample'], # веса классов
#     'ccp_alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], # параметр контроля сжатия дерева
#     #'max_samples': [None] # максимальное количество образцов для обучения каждого дерева
# }
# 
# # подбираем лучшие параметры
# grid_ensemble_randforest = RandomizedSearchCV(
#     RandomForestClassifier(),
#     parameters,
#     scoring='f1',
#     n_jobs = -1
# )
# # обучаем модель
# grid_ensemble_randforest.fit(X_train, y_train)

"""Вывод результата кросс-валидации"""

# результаты кросс-валидации
print(f'Лучшие параметры:\n{grid_ensemble_randforest.best_params_}\n')
print("Показатель f1 для лучшей модели составил: {:.2f}%".
      format(grid_ensemble_randforest.best_score_ * 100) + '\n')

# предсказываем результат на тестовой выборке
grid_ensemble_randforest_pred = grid_ensemble_randforest.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, grid_ensemble_randforest_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, grid_ensemble_randforest_pred)}\n')

"""### **sklearn.ensemble.BaggingClassifier**

---

#### По-умолчанию

Создание и обучение модели
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # создаем модель
# ensemble_bagging = BaggingClassifier()
# 
# # подаем на вход модели обучающие данные
# ensemble_bagging.fit(X_train, y_train)

"""Вывод результата"""

# предсказываем результат на тестовой выборке
ensemble_bagging_pred = ensemble_bagging.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, ensemble_bagging_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, ensemble_bagging_pred)}\n')

"""#### С кросс-валидацией

Проведение процедуры кросс-валидации
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # задаем диапазон параметров
# parameters = {
#     'base_estimator': [None, 'DecisionTreeClassifier', 'RandomForestClassifier'], # базовый оценщик
#     'n_estimators': [10, 50, 100, 200], # количество базовых оценщиков в ансамбле
#     'max_samples': [0.5, 0.75, 1.0], # доля общего количества образцов,
#                                      # используемая при обучении каждого базового оценщика
#     'max_features': [0.5, 0.75, 1.0], # доля общего количества признаков,
#                                       # используемая при обучении каждого базового оценщика
#     #'bootstrap': [True, False], #  следует ли использовать bootstrap-выборку при построении базовых оценщиков
#     #'bootstrap_features': [True, False], # следует ли использовать bootstrap-выборку признаков
#                                          # при обучении каждого базового оценщика
#     'oob_score': [True, False] # следует ли использовать out-of-bag (OOB) оценку для оценки качества модели
# }
# 
# # подбираем лучшие параметры
# grid_ensemble_randforest = RandomizedSearchCV(
#     RandomForestClassifier(),
#     parameters,
#     scoring='f1',
#     n_jobs = -1
# )
# # обучаем модель
# grid_ensemble_randforest.fit(X_train, y_train)

"""Вывод результата кросс-валидации"""

# результаты кросс-валидации
print(f'Лучшие параметры:\n{grid_ensemble_randforest.best_params_}\n')
print("Показатель f1 для лучшей модели составил: {:.2f}%".
      format(grid_ensemble_randforest.best_score_ * 100) + '\n')

# предсказываем результат на тестовой выборке
grid_ensemble_randforest_pred = grid_ensemble_randforest.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, grid_ensemble_randforest_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, grid_ensemble_randforest_pred)}\n')

"""### **sklearn.ensemble.GradientBoostingClassifier**

---

#### По-умолчанию

Создание и обучение модели
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # создаем модель
# ensemble_gradboost = GradientBoostingClassifier()
# 
# # подаем на вход модели обучающие данные
# ensemble_gradboost.fit(X_train, y_train)

"""Вывод результата"""

# предсказываем результат на тестовой выборке
ensemble_gradboost_pred = ensemble_gradboost.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, ensemble_gradboost_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, ensemble_gradboost_pred)}\n')

"""#### С кросс-валидацией

Проведение процедуры кросс-валидации
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # задаем диапазон параметров
# parameters = {
#     "loss": ["deviance", "exponential", "log_loss"], # функция потерь
#     "learning_rate": [0.01, 0.05, 0.1, 0.2], # скорость обучения
#     #"min_samples_split": np.linspace(0.1, 0.5, 12), # минимальное количество образцов для разделения узла
#     #"min_samples_leaf": np.linspace(0.1, 0.5, 12), # минимальное количество образцов для листа
#     #"max_depth": [3, 5, 8], # максимальная глубина дерева
#     "max_features": ["log2", "sqrt"], # количество признаков при поиске лучшего разделения
#     "criterion": ["friedman_mse", "mae"], # функция для измерения качества разделения
#     "subsample": [0.5, 0.95, 1.0], # доля от общего количества образцов,
#                                                           # используемая при обучения каждого дерева
#     "n_estimators": [100, 200] # количество деревьев в ансамбле
# }
# # подбираем лучшие параметры
# grid_ensemble_gradboost = RandomizedSearchCV(
#     GradientBoostingClassifier(),
#     parameters,
#     scoring='f1',
#     n_jobs = -1
# )
# # обучаем модель
# grid_ensemble_gradboost.fit(X_train, y_train)

"""Вывод результата кросс-валидации"""

# результаты кросс-валидации
print(f'Лучшие параметры:\n{grid_ensemble_gradboost.best_params_}\n')
print("Показатель f1 для лучшей модели составил: {:.2f}%".
      format(grid_ensemble_gradboost.best_score_ * 100) + '\n')

# предсказываем результат на тестовой выборке
grid_ensemble_gradboost_pred = grid_ensemble_gradboost.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, grid_ensemble_gradboost_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, grid_ensemble_gradboost_pred)}\n')

"""# **ЛР6**

## Описание

Задание 1 . Провести классификацию найденного датасета, методами CatBoost. В формате *Markdown* написать пояснения. Объяснить почему были выбраны именно такие гиперпараметры, была ли перекрестная проверка, и т.д.
<br><br>
P.S. Все решения выполнять в формате *Jupyter Notebook* и выкладывать на свои гитхабы.

## Решение

### Подключение модулей

Подключение модуля классификатора
"""

# основной модуль классификатора
from catboost import CatBoostClassifier

"""### **catboost.CatBoostClassifier**

---

#### По-умолчанию

Создание и обучение модели
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # создаем модель
# catboost = CatBoostClassifier()
# 
# # подаем на вход модели обучающие данные
# catboost.fit(X_train, y_train)

"""Вывод результата"""

# предсказываем результат на тестовой выборке
catboost_pred = catboost.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, catboost_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, catboost_pred)}\n')

"""#### С кросс-валидацией

Проведение процедуры кросс-валидации
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # задаем диапазон параметров
# # задаем параметры
# parameters = {
#     'depth': [5, 10], # максимальная глубина дерева
#     'learning_rate': [0.01, 0.1], # скорость обучения
#     'iterations': [10, 100], # количество итераций
#     'l2_leaf_reg': [1, 10], # коэффициент L2 регуляризации листьев
#     'border_count': [1, 255], # количество границ для числовых признаков
#     'loss_function': ['Logloss', 'CrossEntropy', 'MultiClass', 'MultiClassOneVsAll'], # функция потерь
#     'random_strength': [0, 1], # сила случайности в выборе признаков на каждом уровне
#     'bagging_temperature': [0, 1], # температура для баггинга
#     'od_type': ['IncToDec', 'Iter', 'None'], # тип оптимизации
#     'od_wait': [10, 100] # количество итераций между проверками оптимизации
# }
# 
# # подбираем лучшие параметры
# grid_catboost = RandomizedSearchCV(
#     CatBoostClassifier(),
#     parameters,
#     scoring='f1',
#     n_jobs = -1
# )
# # обучаем модель
# grid_catboost.fit(X_train, y_train)

"""Вывод результата кросс-валидации"""

# результаты кросс-валидации
print(f'Лучшие параметры:\n{grid_catboost.best_params_}\n')
print("Показатель f1 для лучшей модели составил: {:.2f}%".
      format(grid_catboost.best_score_ * 100) + '\n')

# предсказываем результат на тестовой выборке
grid_catboost_pred = grid_catboost.predict(X_test)

# оцениваем модель
print(f'Сравнение метрик: \n{classification_report(y_test, grid_catboost_pred)}\n')
print(f'Матрица ошибок: \n{confusion_matrix(y_test, grid_catboost_pred)}\n')